# %% [markdown]
# ## Setup and Installation

# %%
# ::: Code Generated by Copilot [550e8400-e29b-41d4-a716-446655440001]. This comment will be removed automatically after the file is saved :::
import torch
from kokoro import KPipeline
import soundfile as sf
from IPython.display import Audio
import os
from datetime import datetime
import numpy as np

# Check device
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# %% [markdown]
# ## Initialize Kokoro TTS Pipeline

# %%
# ::: Code Generated by Copilot [550e8400-e29b-41d4-a716-446655440001]. This comment will be removed automatically after the file is saved :::
# Initialize pipeline with American English
pipeline = KPipeline(lang_code='a', device=device)
print("Kokoro TTS pipeline initialized successfully")

# %% [markdown]
# ### Constants

# %%
sample_text = """
Artificial intelligence has revolutionized the way we live, work, and communicate in the modern world. 
From healthcare diagnostics to personalized entertainment recommendations, AI systems are now deeply 
integrated into our daily routines. Machine learning algorithms analyze vast amounts of data to identify 
patterns and make predictions with remarkable accuracy. Natural language processing enables computers to 
understand and generate human speech, making human-computer interaction more intuitive and seamless.
""".strip()

sr = 24000

# %%
def generate_audio():
    generator = pipeline(sample_text, voice='af_heart')
    audio_segments = []

    for i, (gs, ps, audio) in enumerate(generator):
        # print(f"Segment {i}: {len(audio)} samples")
        audio_segments.append(audio)

    # Concatenate all segments
    audio = np.concatenate(audio_segments)

    # print(f"Total duration: {len(audio) / sr:.2f} seconds")
    # print(f"Audio shape: {audio.shape}")
    
    return Audio(audio, rate=sr)

# %%
def create_audio_file(audio):
    output_dir = 'kokoro_outputs'
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = os.path.join(output_dir, f'kokoro_500word_{timestamp}.wav')
    # Save audio
    sf.write(output_file, audio, sr)
    return output_file


